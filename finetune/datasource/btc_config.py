import os

class BTCConfig:
    """
    Configuration class for BTC fine-tuning.
    """

    def __init__(self):
        # =================================================================
        # Data & Feature Parameters
        # =================================================================
        # BTCæ•°æ®å‚æ•°
        self.symbol = 'BTCUSDT'
        self.data_source = 'binance'  # ä½¿ç”¨Binanceæ•°æ®æº
        
        # æ—¶é—´èŒƒå›´è®¾ç½®
        self.dataset_begin_time = "2025-08-01"
        self.dataset_end_time = '2025-09-10'
        
        # æ»‘åŠ¨çª—å£å‚æ•°
        self.lookback_window = 360  # 15å¤©å†å²æ•°æ®(1hé—´éš”: 15*24=360)
        self.predict_window = 24   # 24å°æ—¶é¢„æµ‹çª—å£
        self.max_context = 512     # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
        
        # ç‰¹å¾åˆ—è¡¨ (OHLCV + Amount)
        self.feature_list = ['open', 'high', 'low', 'close', 'vol', 'amt']
        # æ—¶é—´ç‰¹å¾ï¼ˆæ·»åŠ å¹´ä»½ä»¥æé«˜æ—¶é—´ç²¾åº¦ï¼‰
        self.time_feature_list = ['minute', 'hour', 'weekday', 'day', 'month', 'year']
        
        # =================================================================
        # Dataset Splitting & Paths
        # =================================================================
        # è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ—¶é—´èŒƒå›´2
        self.train_time_range = ["2025-08-01", "2025-09-10"]  # 4å¹´è®­ç»ƒæ•°æ®
        self.val_time_range = ["2025-02-01", "2025-08-01"]    # éªŒè¯é›†æœ‰é‡å 
        self.test_time_range = ["2025-08-01", "2025-09-10"]   # æµ‹è¯•é›†
        self.backtest_time_range = ["2025-08-01", "2025-09-10"] # å›æµ‹æœŸé—´
        
        # æ•°æ®é›†ä¿å­˜è·¯å¾„
        self.dataset_path = "/Users/longquan/Documents/git_repository/myself/kronos/data/processed_datasets"
        
        # =================================================================
        # Training Hyperparameters  
        # =================================================================
        self.clip = 5.0  # æ•°æ®å½’ä¸€åŒ–è£å‰ªå€¼
        
        self.epochs = 20  # BTCæ•°æ®æ³¢åŠ¨æ€§é«˜ï¼Œå‡å°‘epoché˜²æ­¢è¿‡æ‹Ÿåˆ
        self.log_interval = 10  # æ›´é¢‘ç¹çš„æ—¥å¿—è®°å½•
        self.batch_size = 64   # é€‚ä¸­çš„batch size
        
        # æ¯ä¸ªepochçš„æ ·æœ¬æ•°
        self.n_train_iter = 20000 * self.batch_size
        self.n_val_iter = 80 * self.batch_size
        
        # å­¦ä¹ ç‡ (BTCæ•°æ®éœ€è¦æ›´å°çš„å­¦ä¹ ç‡)
        self.tokenizer_learning_rate = 4e-4
        # self.predictor_learning_rate = 2e-5
        self.predictor_learning_rate = 8e-4
        
        # æ¢¯åº¦ç´¯ç§¯
        self.accumulation_steps = 2  # å¢åŠ æœ‰æ•ˆbatch size
        
        # AdamWå‚æ•°
        self.adam_beta1 = 0.9
        self.adam_beta2 = 0.95
        self.adam_weight_decay = 0.1
        
        # éšæœºç§å­
        self.seed = 42
        
        # =================================================================
        # Experiment Logging & Saving
        # =================================================================
        self.use_comet = False  # å¯ä»¥è®¾ç½®ä¸ºTrueå¦‚æœä½ æœ‰Comet MLè´¦å·
        self.comet_config = {
            "api_key": "YOUR_COMET_API_KEY",
            "project_name": "Kronos-BTC-Finetune",
            "workspace": "your_workspace"
        }
        self.comet_tag = 'btc_finetune'
        self.comet_name = 'btc_finetune_experiment'
        
        # æ¨¡å‹ä¿å­˜è·¯å¾„
        self.save_path = "/Users/longquan/Documents/git_repository/myself/kronos_zzzz/dataset/outputs/btc_models"
        self.tokenizer_save_folder_name = 'btc_finetune_tokenizer'
        self.predictor_save_folder_name = 'btc_finetune_predictor'
        self.backtest_save_folder_name = 'btc_finetune_backtest'
        
        # å›æµ‹ç»“æœè·¯å¾„
        self.backtest_result_path = "/Users/longquan/Documents/git_repository/myself/kronos_zzzz/dataset/outputs/btc_backtest_results"
        
        # =================================================================
        # Model & Checkpoint Paths
        # =================================================================
        # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ (ä½¿ç”¨HuggingFace Hub)
        self.pretrained_tokenizer_path = "/Users/longquan/Documents/git_repository/myself/kronos_zzzz/NeoQuasar/Kronos-Tokenizer-base"
        self.pretrained_predictor_path = "/Users/longquan/Documents/git_repository/myself/kronos_zzzz/NeoQuasar/Kronos-base"  # å¯ä»¥é€‰æ‹©smallæˆ–base
        self.pretrained_tokenizer_path = "/Users/longquan/Documents/git_repository/myself/kronos_zzzz/NeoQuasar/Kronos-Tokenizer-base"
        # å¾®è°ƒåæ¨¡å‹è·¯å¾„
        self.finetuned_tokenizer_path = f"{self.save_path}/{self.tokenizer_save_folder_name}/checkpoints/best_model"
        self.finetuned_predictor_path = f"{self.save_path}/{self.predictor_save_folder_name}/checkpoints/best_model"
        

        
    def get_data_intervals(self):
        """è¿”å›ä¸åŒé˜¶æ®µçš„æ•°æ®æ—¶é—´é—´éš”"""
        return {
            'train': self.train_time_range,
            'val': self.val_time_range, 
            'test': self.test_time_range,
            'backtest': self.backtest_time_range
        }
    
    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("="*60)
        print("ğŸš€ BTC Fine-tuning Configuration")
        print("="*60)
        print(f"ğŸ“Š Symbol: {self.symbol}")
        print(f"â° Data Range: {self.dataset_begin_time} to {self.dataset_end_time}")
        print(f"ğŸ¯ Train Range: {self.train_time_range[0]} to {self.train_time_range[1]}")
        print(f"âœ… Val Range: {self.val_time_range[0]} to {self.val_time_range[1]}")
        print(f"ğŸ§ª Test Range: {self.test_time_range[0]} to {self.test_time_range[1]}")
        print(f"ğŸ“ˆ Features: {self.feature_list}")
        print(f"âš™ï¸  Lookback: {self.lookback_window}h, Predict: {self.predict_window}h")
        print(f"ğŸ“ Epochs: {self.epochs}, Batch Size: {self.batch_size}")
        print(f"ğŸ“š Pretrained: {self.pretrained_predictor_path}")
        print(f"ğŸ’¾ Save Path: {self.save_path}")
        print("="*60)

if __name__ == '__main__':
    # æµ‹è¯•é…ç½®
    config = BTCConfig()
    config.print_config_summary()